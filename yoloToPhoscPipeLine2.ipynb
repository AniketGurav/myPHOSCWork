{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0ddae5",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "THIS SCRIPT USES YOLO3 TO LOCALISE THE WORDS AND EXTRACTS CROPS FROM THE\n",
    "ORIGINAL IMAGE..\n",
    "\n",
    "It also includes PHOSCNET\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(\"\\n\\t tf:\",tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "#from yolov3.dataset import Dataset\n",
    "from yolov3.yolov4 import compute_loss1\n",
    "from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from yolov3.utils import read_class_names, image_preprocess#,draw_bbox\n",
    "from yolov3.yolov3 import bbox_iou\n",
    "from yolov3.configs import *\n",
    "from yolov3.utils import load_yolo_weights, detect_image,  nms, read_class_names #image_preprocesss,\n",
    "from supportFunctions import draw_bbox, postprocess_boxes\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from yoloModify import yolo33\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "data exploration\n",
    "\"\"\"\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "    this contains coordinate and words inside BB, No file name mentioned\n",
    "\"\"\"\n",
    "f = open(\"./data/tempCord.json\")\n",
    "tempCord1 = json.load(f)\n",
    "\"\"\"\n",
    "    this contains word and its PHOSC representation\n",
    "\"\"\"\n",
    "with open('filename.pickle', 'rb') as handle:\n",
    "    tempText1 = pickle.load(handle)\n",
    "\n",
    "\n",
    "'''\n",
    "    more details regarding Dataset1 is in yolo3PhoscModify2.ipynb\n",
    "'''\n",
    "\n",
    "from yolov3.dataset import Dataset1\n",
    "from yolov3.yolov3 import Create_Yolov3\n",
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "#trainset = Dataset1('train')\n",
    "testset = Dataset1('test')\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "steps_per_epoch = len(testset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447887a",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    loading of yolo model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf950f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov3.yolov4 import Create_YoloPhosc\n",
    "TRAIN_MODEL_NAME='yolov3_custom'\n",
    "TRAIN_MODEL_NAME\n",
    "\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    #Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    Darknet = Create_Yolov3(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "    #print(\"Darknet_weights=\",os.path.isfile(Darknet_weights))\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    \n",
    "#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "#yolo=Create_Yolov3(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "yolo=yolo33(input_size=416, channels=3, training=True, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "TRAIN_FROM_CHECKPOINT=True\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        print(\"\\n\\t load weights!!!\")\n",
    "        yolo.load_weights(f\"./checkpoints/{TRAIN_MODEL_NAME}\")\n",
    "        print(\"\\n\\t loading complete\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "'''\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d2d2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(counter,image_data, target,orgPath,orgImgName,df):\n",
    "    \n",
    "        \n",
    "    pred_result = yolo(image_data, training=False)\n",
    "\n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "        \n",
    "        if i>0:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "                                \n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "\n",
    "    \n",
    "#         print(\"\\n\\t\\t conv pred:\",conv.shape)\n",
    "#         print(\"\\n\\t\\t pred pred=\",pred.shape)\n",
    "    \n",
    "\n",
    "        ''' \n",
    "            (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "\n",
    "            pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "            pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "             #2.pred_result: (1, 52, 52, 2325)\n",
    "            conv: (1, 26, 26, 18)\n",
    "            pred = (1, 26, 26, 3, 6)\n",
    "            pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "            image_data= (1, 416, 416, 3)\n",
    "            pred = (1, 52, 52, 3, 6)\n",
    "            pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "        '''\n",
    "\n",
    "    \n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        #print(\"\\n\\t 1.pred_bbox pred=\",len(pred_bbox))\n",
    "\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "        \n",
    "        label=target[i][0]\n",
    "        print(\"\\n\\t label shape:\",label.shape)\n",
    "        label=label.reshape(-1,775)\n",
    "        print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape,\"\\t label.shape:\",label.shape)\n",
    "        \n",
    "        if 0:\n",
    "            accuracyCalc(pred_bbox,label)\n",
    "        \n",
    "        \n",
    "        if 1:\n",
    "\n",
    "            \n",
    "            orgImage=cv2.imread(orgPath)\n",
    "            orgImage2=cv2.imread(orgPath)\n",
    "\n",
    "            \n",
    "            #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "            bboxes = postprocess_boxes(pred_bbox, image2.numpy(),orgImage, YOLO_INPUT_SIZE,0.25)\n",
    "\n",
    "            \n",
    "            #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "            #bboxes = postprocess_boxes(pred_bbox, image2.numpy(), YOLO_INPUT_SIZE,0.25)\n",
    "            #print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "\n",
    "            if 0:#i==0:\n",
    "                label=target[i]\n",
    "                print(\"\\n\\t label:\",len(label))\n",
    "                print(\"\\n\\t label0:\",label[0].shape)\n",
    "                print(\"\\n\\t label0:\",label[1].shape)\n",
    "                #print(\"\\n\\t\\t\\ label\",label[])\n",
    "                abboxes = postprocess_boxes_Anchors(label[0],pred_bbox, image2.numpy(),416,0.25)\n",
    "\n",
    "\n",
    "            bboxes = nms(bboxes, 0.1, method='nms')\n",
    "\n",
    "            #print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "            #print(\"\\n\\t after nms 2.bboxes =\",bboxes)\n",
    "            #draw_bbox() missing 1 required positional argument: 'bboxes\n",
    "\n",
    "            \n",
    "            #draw_bbox(nm,counter,level, image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence=True,Text_colors=(255, 255, 0), rectangle_colors='', tracking=False)\n",
    "            \n",
    "            #print(\"\\n\\t bboxes len:\",len(bboxes))\n",
    "            \n",
    "            orgImage=cv2.imread(orgPath)\n",
    "            \n",
    "            #resultImage = draw_bbox(nm,counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "            resultImage = draw_bbox(nm,counter,i,orgImage,orgImgName, bboxes,df, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "\n",
    "            cv2.imwrite(f'./pipeLine/{orgImgName}.png',resultImage)\n",
    "\n",
    "            cv2.imwrite(f'./validation/{orgImgName}.png',resultImage)\n",
    "            #cv2.imwrite(f'./validation/{counter}.png',orgImage)\n",
    "\n",
    "            #input(\"check\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b353d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m02-102.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_result\n",
    "forcePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest//\"\n",
    "forceTestImages=os.listdir(forcePath)\n",
    "forceTestImages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94fdcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-049.png']\n",
      "orgImgName: m01-049.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-060.png']\n",
      "orgImgName: m01-060.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-079.png']\n",
      "orgImgName: m01-079.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-084.png']\n",
      "orgImgName: m01-084.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-090.png']\n",
      "orgImgName: m01-090.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-095.png']\n",
      "orgImgName: m01-095.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-104.png']\n",
      "orgImgName: m01-104.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-110.png']\n",
      "orgImgName: m01-110.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-115.png']\n",
      "orgImgName: m01-115.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-121.png']\n",
      "orgImgName: m01-121.png\n",
      " folder present hence skipped!!!\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-125.png']\n",
      "orgImgName: m01-125.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m01-125.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-131.png']\n",
      "orgImgName: m01-131.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m01-131.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-136.png']\n",
      "orgImgName: m01-136.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m01-136.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-149.png']\n",
      "orgImgName: m01-149.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m01-149.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m01-160.png']\n",
      "orgImgName: m01-160.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m01-160.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-048.png']\n",
      "orgImgName: m02-048.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-048.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-052.png']\n",
      "orgImgName: m02-052.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-052.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-055.png']\n",
      "orgImgName: m02-055.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-055.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-059.png']\n",
      "orgImgName: m02-059.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-059.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-066.png']\n",
      "orgImgName: m02-066.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-066.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-069.png']\n",
      "orgImgName: m02-069.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-069.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-072.png']\n",
      "orgImgName: m02-072.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-072.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-075.png']\n",
      "orgImgName: m02-075.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-075.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-080.png']\n",
      "orgImgName: m02-080.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-080.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-083.png']\n",
      "orgImgName: m02-083.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-083.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-087.png']\n",
      "orgImgName: m02-087.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-087.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-090.png']\n",
      "orgImgName: m02-090.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-090.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-095.png']\n",
      "orgImgName: m02-095.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-095.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-102.png']\n",
      "orgImgName: m02-102.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-102.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-106.png']\n",
      "orgImgName: m02-106.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-106.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-109.png']\n",
      "orgImgName: m02-109.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-109.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m02-112.png']\n",
      "orgImgName: m02-112.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m02-112.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-006.png']\n",
      "orgImgName: m03-006.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-006.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-013.png']\n",
      "orgImgName: m03-013.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-013.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-020.png']\n",
      "orgImgName: m03-020.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-020.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-033.png']\n",
      "orgImgName: m03-033.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-033.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-062.png']\n",
      "orgImgName: m03-062.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-062.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-095.png']\n",
      "orgImgName: m03-095.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-095.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-110.png']\n",
      "orgImgName: m03-110.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-110.png\n",
      "00 ['/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest/m03-114.png']\n",
      "orgImgName: m03-114.png\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      " original image name: m03-114.png\n"
     ]
    }
   ],
   "source": [
    "# for counter,(image_data, target,allImagesName) in enumerate(trainset):\n",
    "from supportFunctions import draw_bbox, postprocess_boxes\n",
    "\n",
    "imgPaths=\"/home/aniketag/Documents/phd/yolov5/data//datasets//forms//\"\n",
    "\n",
    "#filePath=\"./data/data3_phosc.csv\"\n",
    "\n",
    "filePath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/data_444_april.csv\"\n",
    "testCropPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops//\"\n",
    "presentCrop=os.listdir(testCropPath)\n",
    "\n",
    "df=pd.read_csv(filePath)\n",
    "unqImgNames=list(set(df[\"image_name\"]))\n",
    "len(unqImgNames)\n",
    "\n",
    "for counter,(image_data, target,allImagesName) in enumerate(testset):\n",
    "    \n",
    "    \n",
    "    nm=str(np.random.randint(10000))+\".png\"\n",
    "    nm=str(counter)+\".png\"\n",
    "    '''\n",
    "    print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "    print(\"\\n\\t target:\",target[0][0].shape)\n",
    "    print(\"\\n\\t target:\",target[1][0].shape)\n",
    "    print(\"\\n\\t target:\",target[2][0].shape)\n",
    "    '''\n",
    "    #print(\"\\n\\t allImagesName:\",allImagesName)\n",
    "    \n",
    "    #orgImgName=allImagesName[0].split(\"forms/\")[1]\n",
    "    \n",
    "    print(\"00\",allImagesName)\n",
    "    orgImgName=allImagesName[0].split(\"phoscTest/\")[1]\n",
    "    #orgImgName=allImagesName[0].split(\"forms/\")[1]\n",
    "    orgPath=imgPaths+orgImgName\n",
    "    \n",
    "    if orgImgName not in unqImgNames:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        print(\"orgImgName:\",orgImgName)\n",
    "        #input(\"check!!!\")\n",
    "    \n",
    "    if orgImgName in presentCrop:\n",
    "        print(\" folder present hence skipped!!!\")\n",
    "        continue    \n",
    "    \n",
    "    validate_step(counter,image_data, target,orgPath,orgImgName,df)\n",
    "    #input(\"check!!!\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a43b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>org_x1</th>\n",
       "      <th>org_y1</th>\n",
       "      <th>org_x2</th>\n",
       "      <th>org_y2</th>\n",
       "      <th>text</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>phoc</th>\n",
       "      <th>phos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>l04-087.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>361</td>\n",
       "      <td>587</td>\n",
       "      <td>480</td>\n",
       "      <td>652</td>\n",
       "      <td>it</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>l04-087.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>507</td>\n",
       "      <td>600</td>\n",
       "      <td>550</td>\n",
       "      <td>648</td>\n",
       "      <td>his</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1. 0. 1. 0. 1. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>l04-087.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>603</td>\n",
       "      <td>603</td>\n",
       "      <td>689</td>\n",
       "      <td>652</td>\n",
       "      <td>imagination</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ 0.  1.  4.  0.  1.  0.  4. 10.  0.  0.  1.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>l04-087.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>768</td>\n",
       "      <td>593</td>\n",
       "      <td>1120</td>\n",
       "      <td>686</td>\n",
       "      <td>or</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>l04-087.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>1164</td>\n",
       "      <td>620</td>\n",
       "      <td>1209</td>\n",
       "      <td>648</td>\n",
       "      <td>was</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   image_name  class  width  height  org_x1  org_y1  org_x2  \\\n",
       "0           0  l04-087.png      1   2479    3542     361     587     480   \n",
       "1           1  l04-087.png      1   2479    3542     507     600     550   \n",
       "2           2  l04-087.png      1   2479    3542     603     603     689   \n",
       "3           3  l04-087.png      1   2479    3542     768     593    1120   \n",
       "4           4  l04-087.png      1   2479    3542    1164     620    1209   \n",
       "\n",
       "   org_y2         text     x     y     w     h  \\\n",
       "0     652           it  0.17  0.17  0.05  0.02   \n",
       "1     648          his  0.21  0.18  0.02  0.01   \n",
       "2     652  imagination  0.26  0.18  0.03  0.01   \n",
       "3     686           or  0.38  0.18  0.14  0.03   \n",
       "4     648          was  0.48  0.18  0.02  0.01   \n",
       "\n",
       "                                                phoc  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                phos  \n",
       "0  [0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. ...  \n",
       "1  [1. 0. 1. 0. 1. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. ...  \n",
       "2  [ 0.  1.  4.  0.  1.  0.  4. 10.  0.  0.  1.  ...  \n",
       "3  [0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. ...  \n",
       "4  [0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filePath=\"./data/data3_phosc.csv\"\n",
    "df1=pd.read_csv(filePath)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a61584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')\n",
    "\n",
    "ra = Rectangle(3., 3., 5., 5.)\n",
    "rb = Rectangle(1., 1., 4., 3.5)\n",
    "# intersection here is (3, 3, 4, 3.5), or an area of 1*.5=.5\n",
    "\n",
    "def area(a, b):  # returns None if rectangles don't intersect\n",
    "    dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin)\n",
    "    dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        return dx*dy\n",
    "\n",
    "print(area(ra, rb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filePath=\"./data/data3_phosc.csv\"\n",
    "#df1=pd.read_csv(filePath)\n",
    "filterinfDataframe = df1[df1['image_name'] ==\"g06-018o.png\"]\n",
    "#x1,y1,x2,y2=filterinfDataframe[],filterinfDataframe[],filterinfDataframe[],filterinfDataframe[],\n",
    "\n",
    "filterinfDataframe1 =filterinfDataframe[[\"org_x1\",\"org_y1\",\"org_x2\",\"org_y2\",\"text\"]]\n",
    "#g06-018o.png_25_[321, 1098, 404, 1174]\n",
    "for indx,row in filterinfDataframe1.iterrows():\n",
    "    x1,y1,x2,y2,text=row\n",
    "    #print(\"text:\",x1,y1,x2,y2)\n",
    "    \n",
    "    ra = Rectangle(321, 1098, 404, 1174)\n",
    "    rb = Rectangle(x1,y1,x2,y2)\n",
    "\n",
    "    if area(ra, rb):\n",
    "        print(\"text:\",x1,y1,x2,y2)\n",
    "        input(\"check!!!\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterinfDataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ebae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 10:40:02.094391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-08 10:40:02.094412: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/aniketag/.conda/envs/TensorFlow-2.x-YOLOv3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from phoscPipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b562ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 10:40:10.829091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-08 10:40:10.829132: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 10:40:10.829173: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aniketag-Latitude-7420): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 10:40:10.829471: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "MODEL=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/new_IAM_16_\"\n",
    "model.load_weights(MODEL+\".h5\")\n",
    "#model=tf.keras.models.load_model(MODEL+\".h5\")\n",
    "#print(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b05bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "testImgPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data//IAM_test//\"\n",
    "\n",
    "testImgNames=os.listdir(testImgPath)\n",
    "\n",
    "print(\" No of test images:\",len(testImgNames))\n",
    "testImgNames[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fdc2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Image  Word      Writer\n",
      "0  n02-154-04-05.png  that  n02-154-04\n",
      "1  m04-093-02-01.png    it  m04-093-02\n",
      "2  p03-135-03-07.png   his  p03-135-03\n",
      "3  n04-044-01-08.png  been  n04-044-01\n",
      "4  p02-022-07-07.png   the  p02-022-07\n",
      "               Image       Word      Writer\n",
      "0  m04-209-01-05.png  surprised  m04-209-01\n",
      "1  m04-019-06-04.png    lording  m04-019-06\n",
      "2  n06-128-04-05.png    shallow  n06-128-04\n",
      "3  n01-020-04-01.png     summit  n01-020-04\n",
      "4  m03-062-00-02.png  repulsive  m03-062-00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_csv_file1=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data//IAM_test_seen.csv\"\n",
    "test_csv_file2=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data/IAM_test_unseen.csv\"\n",
    "\n",
    "df_test1=pd.read_csv(test_csv_file1)\n",
    "df_test2=pd.read_csv(test_csv_file2)\n",
    "\n",
    "print(df_test1.head(5))\n",
    "print(df_test2.head(5))\n",
    "\n",
    "#test_word_label=get_comb_label(list(set(df_test['Word'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f8471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    returns a dictionary having word as a key and PHOSC representation as a value\n",
    "\"\"\"\n",
    "\n",
    "def get_comb_label(x):\n",
    "    phos_labels=gen_label(x)\n",
    "    phoc_labels=gen_phoc_label(x)\n",
    "    test_labels=dict()\n",
    "    for x in phos_labels:\n",
    "        test_labels[x]=np.concatenate((phos_labels[x],phoc_labels[x]),axis=0)\n",
    "    return test_labels\n",
    "\n",
    "#train_word_label=get_comb_label(list(set(df_lex['Word'])))\n",
    "\n",
    "def similarity(x,y):\n",
    "    return 1000*np.dot(x,y)/(LA.norm(x)*LA.norm(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb2d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "from phos_label_generator import *\n",
    "\n",
    "#test_word_label=get_comb_label(list(set(df_test1['Word'])))\n",
    "#test_word_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a78fbb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m    test data from PHOSCNET\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx,row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_test1\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      8\u001b[0m     word\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWord\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindx:\u001b[39m\u001b[38;5;124m\"\u001b[39m,indx,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m word=\u001b[39m\u001b[38;5;124m\"\u001b[39m,word)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test1' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    test data from PHOSCNET\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for indx,row in df_test1.iterrows():\n",
    "    \n",
    "    word=row['Word']\n",
    "    print(\"indx:\",indx,\" word=\",word)\n",
    "    path2Image=testImgPath+row[\"Image\"]   \n",
    "\n",
    "    x=img_to_array(load_img(path2Image))\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y_pred=model.predict(x)\n",
    "    y_pred=np.squeeze(np.concatenate((y_pred[0],y_pred[1]),axis=1))\n",
    "    #print(y_pred)\n",
    "    mx=0\n",
    "    for k in test_word_label:\n",
    "        temp=similarity(y_pred,test_word_label[k])\n",
    "        if temp>mx:\n",
    "            mx=temp\n",
    "            op=k\n",
    "    print(\"\")\n",
    "    print(\" original word:\",word,\"-->\",op,mx)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "path2Image=testImgPath+testImgNames[0]\n",
    "x=img_to_array(load_img(path2Image))\n",
    "\n",
    "x = np.expand_dims(x, axis=0)\n",
    "y_pred=model.predict(x)\n",
    "y_pred=np.squeeze(np.concatenate((y_pred[0],y_pred[1]),axis=1))\n",
    "print(y_pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb905c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_word_label.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33627487",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops/g06-042r.png//'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m allWords\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      9\u001b[0m testImgPath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops/g06-042r.png//\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx,imgName \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestImgPath\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     13\u001b[0m     word\u001b[38;5;241m=\u001b[39mimgName\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m     word\u001b[38;5;241m=\u001b[39mword\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops/g06-042r.png//'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    gather all words\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "allWords=[]\n",
    "\n",
    "testImgPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops/g06-042r.png//\"\n",
    "\n",
    "for indx,imgName in enumerate(os.listdir(testImgPath)):\n",
    "    \n",
    "    word=imgName.split(\"]_\")[1]\n",
    "    word=word.split(\"_.png\")[0]\n",
    "    word= regex.sub('', word)\n",
    "    allWords.append(word)\n",
    "    \n",
    "allWords=list(set(allWords))\n",
    "test_word_label=get_comb_label(allWords)\n",
    "len(allWords)\n",
    "#allWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2e6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path2Image):\n",
    "    \n",
    "    x=img_to_array(load_img(path2Image))\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y_pred=model.predict(x)\n",
    "    y_pred=np.squeeze(np.concatenate((y_pred[0],y_pred[1]),axis=1))\n",
    "    #print(y_pred)\n",
    "    mx=0\n",
    "    for k in test_word_label:\n",
    "        temp=similarity(y_pred,test_word_label[k])\n",
    "        if temp>mx:\n",
    "            mx=temp\n",
    "            op=k\n",
    "            \n",
    "    return op,mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4138e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " original image shape: (3542, 2479, 3)\n",
      " imgName: m01-060.png_44_[1165, 1047, 1443, 1188]_glorious_.png\n",
      " word: glorious  coordinate: 1165 1047 1443 1188  imgName: m01-060.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 10:41:37.949583: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-08 10:41:37.970372: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1804800000 Hz\n",
      "2022-04-08 10:41:38.215488: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2247838208 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "#m01-060.png\n",
    "\n",
    "orgImage=\"m01-060.png\" #\"g06-042r.png\"\n",
    "testImgPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\" \n",
    "testCropPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops//\"+orgImage\n",
    "savePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/final//\"\n",
    "image=cv2.imread(testImgPath+orgImage)\n",
    "print(\" original image shape:\",image.shape)\n",
    "\n",
    "for indx,imgName in enumerate(os.listdir(testCropPath)):\n",
    "    \n",
    "    print(\" imgName:\",imgName)\n",
    "    word=imgName.split(\"]_\")[1]\n",
    "    word=word.split(\"_.png\")[0]\n",
    "    \n",
    "    cor=imgName.split(\"[\")[1]\n",
    "    cor=cor.split(\"]\")[0]\n",
    "    cor=\"[\"+cor+\"]\"\n",
    "    cor=eval(cor)\n",
    "    \n",
    "    x1,y1,x2,y2=int(cor[0]),int(cor[1]),int(cor[2]),int(cor[3])\n",
    "        \n",
    "    imgName=imgName.split(\"_\")[0]\n",
    "    print(\" word:\",word,\" coordinate:\",x1,y1,x2,y2,\" imgName:\",imgName)\n",
    "    \n",
    "    image = cv2.rectangle(image, (x1, y1), (x2, y2),(255,0,0), 3)\n",
    "    \n",
    "    predWord,score=predict(testImgPath+orgImage)\n",
    "    \n",
    "    \n",
    "cv2.imwrite(savePath+orgImage,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59fcda05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(testImagePath+orgImage)\n",
    "testImagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad012cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " imgName: g06-042r.png_32_[330, 951, 661, 1005]_douloureux_.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_598632/1492369126.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1000*np.dot(x,y)/(LA.norm(x)*LA.norm(y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " original word: douloureux --> douloureux 945.5403865329882\n",
      " imgName: g06-042r.png_16_[1337, 1132, 1518, 1174]_death_.png\n",
      "\n",
      " original word: death --> death 994.2022236923053\n",
      " imgName: g06-042r.png_9_[328, 1130, 552, 1187]_himself_.png\n",
      "\n",
      " original word: himself --> himself 959.5919664068653\n",
      " imgName: g06-042r.png_58_[769, 952, 838, 995]_As_.png\n",
      "\n",
      " original word: As --> this 888.3643333732588\n",
      " imgName: g06-042r.png_26_[1209, 961, 1344, 1003]_1830_.png\n",
      "\n",
      " original word: 1830 --> homoeopathy 706.7321201581717\n",
      " imgName: g06-042r.png_37_[869, 950, 1039, 1029]_early_.png\n",
      "\n",
      " original word: early --> early 953.5104232614891\n",
      " imgName: g06-042r.png_38_[1600, 1134, 1704, 1182]_the_.png\n",
      "\n",
      " original word: the --> the 980.6751909386699\n",
      " imgName: g06-042r.png_29_[1762, 1123, 2089, 1184]_new_.png\n",
      "\n",
      " original word: new --> method 811.6437584919781\n",
      " imgName: g06-042r.png_56_[1760, 772, 1868, 818]_the_.png\n",
      "\n",
      " original word: the --> the 951.7018914102316\n",
      " imgName: g06-042r.png_13_[587, 593, 702, 645]_this_.png\n",
      "\n",
      " original word: this --> this 961.9592328875074\n",
      " imgName: g06-042r.png_10_[967, 1310, 1188, 1361]_method_.png\n",
      "\n",
      " original word: method --> method 990.2442191718053\n",
      " imgName: g06-042r.png_47_[328, 1484, 429, 1540]_had_.png\n",
      "\n",
      " original word: had --> had 927.3787283522157\n",
      " imgName: g06-042r.png_20_[1652, 1306, 2054, 1390]_homoeopathy_.png\n",
      "\n",
      " original word: homoeopathy --> homoeopathy 931.7440101887086\n",
      " imgName: g06-042r.png_51_[1215, 776, 1358, 823]_been_.png\n",
      "\n",
      " original word: been --> been 871.1538539137339\n",
      " imgName: g06-042r.png_12_[1079, 977, 1152, 1004]_as_.png\n",
      "\n",
      " original word: as --> as 873.9137355031163\n",
      " imgName: g06-042r.png_1_[987, 1490, 1051, 1537]_to_.png\n",
      "\n",
      " original word: to --> to 907.8991566224787\n",
      " imgName: g06-042r.png_40_[1929, 764, 2049, 823]_6tic_.png\n",
      "\n",
      " original word: 6tic --> notice 823.0412175220212\n",
      " imgName: g06-042r.png_55_[1604, 1125, 1712, 1179]_the_.png\n",
      "\n",
      " original word: the --> the 975.8104895804174\n",
      " imgName: g06-042r.png_0_[881, 792, 1029, 825]_cure_.png\n",
      "\n",
      " original word: cure --> cure 965.0696079525404\n",
      " imgName: g06-042r.png_25_[1292, 593, 1356, 650]_at_.png\n",
      "\n",
      " original word: at --> at 787.6073949369169\n",
      " imgName: g06-042r.png_8_[1900, 951, 2141, 1004]_believed_.png\n",
      "\n",
      " original word: believed --> believed 966.9263395603582\n",
      " imgName: g06-042r.png_14_[1557, 612, 1687, 646]_even_.png\n",
      "\n",
      " original word: even --> even 859.8966931903864\n",
      " imgName: g06-042r.png_31_[1406, 765, 1582, 840]_found_.png\n",
      "\n",
      " original word: found --> found 974.023592333381\n",
      " imgName: g06-042r.png_28_[641, 1311, 924, 1362]_curative_.png\n",
      "\n",
      " original word: curative --> curative 985.0143689683878\n",
      " imgName: g06-042r.png_34_[1973, 602, 2043, 647]_in_.png\n",
      "\n",
      " original word: in --> in 941.7580001020101\n",
      " imgName: g06-042r.png_45_[483, 1499, 617, 1540]_been_.png\n",
      "\n",
      " original word: been --> been 916.2042773876586\n",
      " imgName: g06-042r.png_36_[599, 1135, 674, 1183]_to_.png\n",
      "\n",
      " original word: to --> method 764.0006028650035\n",
      " imgName: g06-042r.png_43_[1606, 949, 1854, 1051]_Anglesey_.png\n",
      "\n",
      " original word: Anglesey --> homoeopathy 772.7500737748635\n",
      " imgName: g06-042r.png_39_[485, 1502, 632, 1540]_been_.png\n",
      "\n",
      " original word: been --> been 995.728993875526\n",
      " imgName: g06-042r.png_48_[1614, 1311, 2052, 1386]_homoeopathy_.png\n",
      "\n",
      " original word: homoeopathy --> homoeopathy 915.913434590171\n",
      " imgName: g06-042r.png_41_[349, 588, 445, 644]_Nor_.png\n",
      "\n",
      " original word: Nor --> Nor 760.4356825006511\n",
      " imgName: g06-042r.png_2_[787, 1149, 865, 1181]_on_.png\n",
      "\n",
      " original word: on --> on 704.0613065317877\n",
      " imgName: g06-042r.png_54_[1429, 594, 1520, 661]_for_.png\n",
      "\n",
      " original word: for --> for 827.9935394922582\n",
      " imgName: g06-042r.png_11_[1248, 1315, 1442, 1361]_known_.png\n",
      "\n",
      " original word: known --> known 954.6507091397099\n",
      " imgName: g06-042r.png_23_[323, 1320, 575, 1362]_German_.png\n",
      "\n",
      " original word: German --> German 807.2741226033883\n",
      " imgName: g06-042r.png_62_[1028, 1136, 1170, 1212]_point_.png\n",
      "\n",
      " original word: point --> point 935.8688060595149\n",
      " imgName: g06-042r.png_60_[873, 955, 1036, 1023]_early_.png\n",
      "\n",
      " original word: early --> early 935.7163310934217\n",
      " imgName: g06-042r.png_15_[678, 1140, 748, 1182]_be_.png\n",
      "\n",
      " original word: be --> believed 805.3657835178379\n",
      " imgName: g06-042r.png_53_[896, 1134, 997, 1182]_the_.png\n",
      "\n",
      " original word: the --> the 982.6791496758829\n",
      " imgName: g06-042r.png_5_[1716, 592, 1901, 662]_today_.png\n",
      "\n",
      " original word: today --> today 981.9762626486361\n",
      " imgName: g06-042r.png_35_[1026, 1128, 1184, 1214]_point_.png\n",
      "\n",
      " original word: point --> point 947.5931282248587\n",
      " imgName: g06-042r.png_3_[1501, 1329, 1572, 1362]_as_.png\n",
      "\n",
      " original word: as --> s 776.9783334277355\n",
      " imgName: g06-042r.png_57_[685, 1488, 928, 1584]_brought_.png\n",
      "\n",
      " original word: brought --> brought 961.5768977264268\n",
      " imgName: g06-042r.png_64_[1409, 767, 1580, 839]_found_.png\n",
      "\n",
      " original word: found --> found 972.1839614465363\n",
      " imgName: g06-042r.png_27_[772, 792, 846, 824]_no_.png\n",
      "\n",
      " original word: no --> no 802.0712054185998\n",
      " imgName: g06-042r.png_33_[506, 594, 557, 637]_is_.png\n",
      "\n",
      " original word: is --> is 794.0215425785505\n",
      " imgName: g06-042r.png_17_[1219, 1493, 1421, 1547]_notice_.png\n",
      "\n",
      " original word: notice --> notice 996.2772665748554\n",
      " imgName: g06-042r.png_21_[519, 776, 695, 824]_1960s_.png\n",
      "\n",
      " original word: 1960s --> as 721.8984957693283\n",
      " imgName: g06-042r.png_49_[1232, 1130, 1292, 1198]_of_.png\n",
      "\n",
      " original word: of --> brought 751.729756034267\n",
      " imgName: g06-042r.png_50_[1093, 1498, 1171, 1540]_his_.png\n",
      "\n",
      " original word: his --> his 882.2592101819023\n",
      " imgName: g06-042r.png_52_[1626, 776, 1715, 835]_for_.png\n",
      "\n",
      " original word: for --> for 862.9045357647904\n",
      " imgName: g06-042r.png_22_[737, 592, 802, 639]_to_.png\n",
      "\n",
      " original word: to --> to 941.6844499206087\n",
      " imgName: g06-042r.png_65_[1028, 1131, 1180, 1212]_point_.png\n",
      "\n",
      " original word: point --> point 956.0472302969508\n",
      " imgName: g06-042r.png_19_[947, 592, 1232, 647]_wondered_.png\n",
      "\n",
      " original word: wondered --> wondered 975.3004986678054\n",
      " imgName: g06-042r.png_63_[684, 1488, 928, 1583]_brought_.png\n",
      "\n",
      " original word: brought --> brought 955.8745380994013\n",
      " imgName: g06-042r.png_42_[1919, 764, 2036, 817]_6tic_.png\n",
      "\n",
      " original word: 6tic --> notice 823.753246104023\n",
      " imgName: g06-042r.png_61_[1082, 777, 1176, 824]_has_.png\n",
      "\n",
      " original word: has --> has 724.7404087727746\n",
      " imgName: g06-042r.png_59_[338, 766, 438, 823]_the_.png\n",
      "\n",
      " original word: the --> the 976.6923720055818\n",
      " imgName: g06-042r.png_44_[831, 595, 908, 639]_be_.png\n",
      "\n",
      " original word: be --> been 833.8161402792766\n",
      " imgName: g06-042r.png_46_[1419, 963, 1561, 1004]_when_.png\n",
      "\n",
      " original word: when --> when 955.5481087557893\n",
      " Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "testImgPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/crops/g06-042r.png//\"\n",
    "match=0\n",
    "\n",
    "for indx,imgName in enumerate(os.listdir(testImgPath)):\n",
    "    \n",
    "    print(\" imgName:\",imgName)\n",
    "    word=imgName.split(\"]_\")[1]\n",
    "    word=word.split(\"_.png\")[0]\n",
    "        \n",
    "    path2Image=testImgPath+imgName   \n",
    "\n",
    "    x=img_to_array(load_img(path2Image))\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y_pred=model.predict(x)\n",
    "    y_pred=np.squeeze(np.concatenate((y_pred[0],y_pred[1]),axis=1))\n",
    "    #print(y_pred)\n",
    "    mx=0\n",
    "    for k in test_word_label:\n",
    "        temp=similarity(y_pred,test_word_label[k])\n",
    "        if temp>mx:\n",
    "            mx=temp\n",
    "            op=k\n",
    "    print(\"\")\n",
    "    print(\" original word:\",word,\"-->\",op,mx)\n",
    "\n",
    "    if word==op:\n",
    "        match+=1\n",
    "    \n",
    "print(\" Accuracy:\",match/(indx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "http://localhost:8888/notebooks/Untitled.ipynb\n",
    "http://localhost:8888/notebooks/yolo3PhoscModify3.ipynb#\n",
    "http://localhost:8888/notebooks/yolo3PhoscModify3ToyData.ipynb\n",
    "http://localhost:8888/notebooks/yolo3PhoscModify2.ipynb\n",
    "http://localhost:8888/notebooks/createData_1.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ebc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6858ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26e889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"./data/data3.csv\")\n",
    "filePath=\"./data/data3_phosc.csv\"\n",
    "df1=pd.read_csv(filePath)\n",
    "unqImgNames=list(set(df1[\"image_name\"]))\n",
    "len(unqImgNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68447bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)\n",
    "import os\n",
    "df=pd.read_csv(\"./data/data3.csv\")\n",
    "\n",
    "imgPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms\"\n",
    "\n",
    "files=os.listdir(imgPath)\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "modifying for working with single image to join with PHOSCNet\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#df.head(5) ./data/data3_phosc.csv\n",
    "import os\n",
    "df=pd.read_csv(\"./data/data3_phosc.csv\") # file name BB and word value is available for this\n",
    "unqImgNames=list(set(df[\"image_name\"]))\n",
    "\n",
    "imgPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\"\n",
    "\n",
    "files=os.listdir(imgPath)\n",
    "files[0]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    read any image and predict yolo3 frame work\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "batch_image = np.zeros((1,416,416, 3), dtype=np.float32)\n",
    "\n",
    "img=cv2.imread(imgPath+'c03-000b.png')\n",
    "print(\"img shape:\",img.shape)\n",
    "img=cv2.resize(img,(416,416))\n",
    "batch_image[0, :, :, :] = img\n",
    "\n",
    "def validate_step2(counter,image_data,orgPath,orgImgName):\n",
    "    \n",
    "    pred_result = yolo(image_data, training=False)\n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "    orgImage=cv2.imread(orgPath+orgImgName)\n",
    "    #orgImage2=cv2.imread(orgPath)\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    \n",
    "    for i in range(grid):\n",
    "        \n",
    "        if i>0:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "                                \n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        #print(\"\\n\\t 1.pred_bbox pred=\",len(pred_bbox))\n",
    "\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "\n",
    "        #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "        bboxes = postprocess_boxes(pred_bbox, image2.numpy(),orgImage, YOLO_INPUT_SIZE,0.25)\n",
    "\n",
    "        bboxes = nms(bboxes, 0.1, method='nms')\n",
    "\n",
    "        #resultImage = draw_bbox(nm,counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "        resultImage = draw_bbox(orgImgName,counter,i,orgImage,orgImgName, bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "\n",
    "        cv2.imwrite(f'./pipeLine/{orgImgName}.png',resultImage)\n",
    "        #cv2.imwrite(f'./validation/{counter}.png',orgImage)\n",
    "\n",
    "        #input(\"check\")\n",
    "\n",
    "batch_image = np.zeros((1,416,416, 3), dtype=np.float32)\n",
    "orgImgName='c03-000b.png'\n",
    "orgPath=imgPath\n",
    "\n",
    "img=cv2.imread(imgPath+orgImgName)\n",
    "print(\"1.img shape:\",img.shape)\n",
    "\n",
    "img=cv2.resize(img,(416,416))\n",
    "batch_image[0, :, :, :] = img\n",
    "\n",
    "#pred_result = yolo(batch_image, training=False)\n",
    "#image2=tf.squeeze(batch_image)p\n",
    "\n",
    "validate_step2(0,batch_image,orgPath,orgImgName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
