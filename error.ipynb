{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e8c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 00:16:23.876207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3) (7, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "from phos_label_generator import gen_label\n",
    "from phoc_label_generator import gen_phoc_label\n",
    "\n",
    "# Setting random seeds\n",
    "\n",
    "random.seed(73)\n",
    "np.random.seed(73) \n",
    "\n",
    "def getphoclabel(x):\n",
    "    return all_phoc_labels[x]\n",
    "\n",
    "def getphoslabel(x):\n",
    "    return all_phos_labels[x]\n",
    "\n",
    "\n",
    "basePath=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main//\"\n",
    "train_csv_file=basePath+\"/data/crop/IAM_train.csv\"\n",
    "\n",
    "valid_csv_file=basePath+\"/data/crop/IAM_train1.csv\"\n",
    "#valid_csv_file=train_csv_file #basePath+\"/data/crop/IAM_valid.csv\" #args['vmap']\n",
    "train_unseen_csv_file= None #args['umap']\n",
    "\n",
    "train_folder= basePath+\"/data/crop//cropYoloV3PhoscTrain//\"\n",
    "valid_folder=basePath+\"/data/crop/IAM_valid\"\n",
    "\n",
    "BATCH_SIZE=1\n",
    "EPOCHS=2\n",
    "\n",
    "df_train=pd.read_csv(train_csv_file,nrows=10000)\n",
    "df_valid=pd.read_csv(valid_csv_file,nrows=10000)\n",
    "\n",
    "print(df_train.shape,df_valid.shape)\n",
    "\n",
    "train_word_phos_label=gen_label(list(set(df_train['Word'])))\n",
    "valid_word_phos_label=gen_label(list(set(df_valid['Word'])))\n",
    "all_phos_labels={**train_word_phos_label,**valid_word_phos_label}\n",
    "train_word_phoc_label=gen_phoc_label(list(set(df_train['Word'])))\n",
    "valid_word_phoc_label=gen_phoc_label(list(set(df_valid['Word'])))\n",
    "all_phoc_labels={**train_word_phoc_label,**valid_word_phoc_label}\n",
    "\n",
    "type(train_word_phos_label)\n",
    "len(train_word_phos_label.keys())\n",
    "\n",
    "df_train['PhosLabel']=df_train['Word'].apply(getphoslabel)\n",
    "df_valid['PhosLabel']=df_valid['Word'].apply(getphoslabel)\n",
    "df_train['PhocLabel']=df_train['Word'].apply(getphoclabel)\n",
    "df_valid['PhocLabel']=df_valid['Word'].apply(getphoclabel)\n",
    "\n",
    "\n",
    "BATCH_SIZE=2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4fb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "class DataSequence(Sequence):\n",
    "    def __init__(self, df, batch_size,dataType):\n",
    "        self.df = df # your pandas dataframe\n",
    "        self.bsz = batch_size # batch size\n",
    "        self.dataType=dataType\n",
    "        \n",
    "        self.basePath=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main//\"\n",
    "        \n",
    "        self.train_folder= basePath+\"/data/crop//cropYoloV3PhoscTrain//\"\n",
    "        self.valid_folder=basePath+\"/data/crop//cropYoloV3PhoscTrain//\" #self.train_folder #basePath+\"/data/crop/IAM_valid//\"\n",
    "\n",
    "        # Take labels and a list of image locations in memory\n",
    "        self.labels=[]\n",
    "        for i in range(len(self.df)):\n",
    "            self.labels.append(\n",
    "                {\"phosnet\":np.asarray(self.df['PhosLabel'].iloc[i]).astype(np.float32),\n",
    "                 \"phocnet\":np.asarray(self.df['PhocLabel'].iloc[i]).astype(np.float32)})\n",
    "\n",
    "\n",
    "        #print(\"\\n\\t labels:\",self.labels)\n",
    "        #print(len(self.labels))\n",
    "        self.im_list = self.df['Image'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        # compute number of batches to yield\n",
    "        return int(math.ceil(len(self.df) / float(self.bsz)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch if in training mode\n",
    "        self.indexes = range(len(self.im_list))\n",
    "        self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "        \n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx * self.bsz: (idx + 1) * self.bsz])\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        #return np.array([img_to_array(load_img(im)) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]])\n",
    "        \n",
    "        if self.dataType==\"train\":\n",
    "            im=self.im_list[idx]\n",
    "            \n",
    "            \n",
    "            print(\"=\"*10)\n",
    "            print(\"1.train:\",os.path.isfile(self.train_folder+im))\n",
    "            \n",
    "            #print(\"\\n 1.file name:\",self.train_folder+im)\n",
    "            \n",
    "            tempImage1=load_img(self.train_folder+im)\n",
    "            tempImage11=cv2.imread(self.train_folder+im)\n",
    "            \n",
    "            #img_to_array(load_img(self.train_folder+im))\n",
    "            print(\"\\n\\t \\t 1.tempImage:\",tempImage1.size,\"#\",tempImage11.shape,\" \\t im:\",im,\" type:\",type(tempImage11))\n",
    "            print(\"\\n\\t \\t 1.tempImage type:\",tempImage11[0,0])      \n",
    "\n",
    "            im=self.im_list[idx+1]\n",
    "            tempImage2=load_img(self.train_folder+im)\n",
    "            tempImage22=cv2.imread(self.train_folder+im)\n",
    "\n",
    "            #print(\"\\n 2.file name:\",self.train_folder+im)\n",
    "\n",
    "            \n",
    "            print(\"2.train:\",os.path.isfile(self.train_folder+im))\n",
    "            print(\"\\n\\t\\t 2.tempImage:\",tempImage2.size,\"#\",tempImage22.shape,\" \\t im:\",im,\" type:\",type(tempImage22))\n",
    "            print(\"\\n\\t \\t 2.tempImage type:\",tempImage22[0,0])\n",
    "            print(\"+\"*10)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            tempList=[]\n",
    "            for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]:\n",
    "                \n",
    "                tempList.append(img_to_array(load_img(self.train_folder+im)))\n",
    "            \"\"\" \n",
    "            \n",
    "            return np.array([img_to_array(load_img(self.train_folder+im,target_size=(50,250))) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]],dtype=object)\n",
    "        \n",
    "        elif self.dataType==\"valid\":\n",
    "            \n",
    "            return np.array([img_to_array(load_img(self.valid_folder+im,target_size=(50,250))) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]],dtype=object)\n",
    "               \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "    \n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        print(\"batch_x\",len(batch_x))\n",
    "        #batch_x =batch_x.astype(np.float32)\n",
    "        #batch_x =np.asarray(batch_x).astype(np.float32)\n",
    "        #np.asarray(x_train).astype(np.float32)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        l1=[]\n",
    "        l2=[]\n",
    "        for x in batch_y:\n",
    "            l1.append(x['phosnet'])\n",
    "            l2.append(x['phocnet'])\n",
    "        #return batch_x, batch_y\n",
    "        return batch_x,{'phosnet':np.asarray(l1),'phocnet':np.asarray(l2)}\n",
    "        #return batch_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba159439",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = DataSequence(df_train, BATCH_SIZE,dataType=\"train\")\n",
    "valid_sequence = DataSequence(df_valid, BATCH_SIZE,dataType=\"valid\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c60e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exp: 0 9999\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "\n",
    "#len(train_sequence)\n",
    "\n",
    "i=0\n",
    "expCount=0\n",
    "noExp=0\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    \n",
    "    \n",
    "    #train_sequence[i][0][0]\n",
    "    \n",
    "    if i<5010:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    #print(\"Image number:\",i,type(train_sequence[i][0][0]),\" \",train_sequence[i][0].shape)\n",
    "    try:\n",
    "        #print(1)\n",
    "        noExp+=1\n",
    "        #train_sequence[i][0][0]\n",
    "        print(type(train_sequence[i][0][0]),\" \",train_sequence[i][0].shape)\n",
    "        #print(type(train_sequence[i][0]),\" \",train_sequence[i][0].dtype)\n",
    "\n",
    "        #img=train_sequence[i][0][0]\n",
    "        #print(train_sequence[i][0][0].dtype)\n",
    "        #print(\"\\t\\t i=\",i)\n",
    "        \n",
    "    except Exception as e:\n",
    "        expCount+=1\n",
    "        print(\" exception:\",e,\" -->\",i,\"expCount:\",expCount)\n",
    "        #input(\"check!!!!!!\")\n",
    "    #input(\" complete!!\")\n",
    "print(\" exp:\",expCount,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c225b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: b04-187.png_62_[315, 1597, 386, 1752]_of_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [244 244 244]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: a01-053x.png_70_[901, 2135, 987, 2214]_to_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [240 240 240]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: a01-053x.png_70_[901, 2135, 987, 2214]_to_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [240 240 240]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: k04-079.png_74_[347, 1481, 489, 1602]_she_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [251 251 251]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: k04-079.png_74_[347, 1481, 489, 1602]_she_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [251 251 251]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: d04-089.png_3_[2114, 924, 2183, 966]_to_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [250 250 250]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: d04-089.png_3_[2114, 924, 2183, 966]_to_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [250 250 250]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: n01-009.png_13_[1441, 917, 1635, 993]_gently_2_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [248 248 248]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: n01-009.png_13_[1441, 917, 1635, 993]_gently_2_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [248 248 248]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: m04-038.png_76_[1778, 1320, 1842, 1399]_to_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [250 250 250]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: m04-038.png_76_[1778, 1320, 1842, 1399]_to_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [250 250 250]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: m04-019.png_76_[590, 2145, 922, 2231]_Mixed_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [247 247 247]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: m04-019.png_76_[590, 2145, 922, 2231]_Mixed_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [247 247 247]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: f01-147.png_12_[1186, 1324, 1311, 1388]_other_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [238 238 238]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: f01-147.png_12_[1186, 1324, 1311, 1388]_other_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [238 238 238]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: g06-026j.png_11_[1433, 708, 1490, 791]_It_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [251 251 251]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: g06-026j.png_11_[1433, 708, 1490, 791]_It_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [251 251 251]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: n04-044.png_51_[332, 1769, 383, 1853]_in_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [249 249 249]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (250, 50) # (50, 250, 3)  \t im: n04-044.png_51_[332, 1769, 383, 1853]_in_3_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [249 249 249]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (266, 96) # (96, 266, 3)  \t im: a01-091u.png_14_[1785, 1473, 2011, 1529]_heavy_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [249 249 249]\n",
      "++++++++++\n",
      "batch_x 2\n",
      "==========\n",
      "1.train: True\n",
      "\n",
      "\t \t 1.tempImage: (266, 96) # (96, 266, 3)  \t im: a01-091u.png_14_[1785, 1473, 2011, 1529]_heavy_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 1.tempImage type: [249 249 249]\n",
      "2.train: True\n",
      "\n",
      "\t\t 2.tempImage: (250, 50) # (50, 250, 3)  \t im: m04-123.png_73_[669, 1731, 803, 1804]_up_1_.png  type: <class 'numpy.ndarray'>\n",
      "\n",
      "\t \t 2.tempImage type: [140 140 140]\n",
      "++++++++++\n",
      "batch_x 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17215/2463212579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "expCount=0\n",
    "noExp=0\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    \n",
    "    if i<5010-20:\n",
    "        continue\n",
    "\n",
    "    train_sequence[i][0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636ba5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72727c50",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    below part check phosc crops data from train dataframe and \n",
    "    only keeps the rows for which corresponding images are present \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0cc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80208024",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/crop/IAM_train.csv\"\n",
    "trainCropPath=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/crop/cropYoloV3PhoscTrain//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631808e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (276363, 3)  column names: Index(['Image', 'Word', 'Writer'], dtype='object')\n",
      " # images: 267247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.DataFrame()\\ndf = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(dfPath)\n",
    "print(\"df.shape:\",df.shape,\" column names:\",df.columnn)\n",
    "\n",
    "allImages=os.listdir(trainCropPath)\n",
    "print(\" # images:\",len(allImages))\n",
    "\n",
    "                   \n",
    "                   \n",
    "\"\"\"\n",
    "df = pd.DataFrame()\n",
    "df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\n",
    "\n",
    "dfNew = dfNew.append({'Image': 'Zed', 'Word': 9, 'Writer': 2}, ignore_index=True)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8ac450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foundImages: 102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "foundImages=0\n",
    "dfNew=pd.DataFrame(columns=['Image', 'Word', 'Writer'])\n",
    "                   \n",
    "for indx,row in df.iterrows():\n",
    "    \n",
    "    imgName=row.Image\n",
    "    \n",
    "    #print(\"imgName:\",imgName)\n",
    "    \n",
    "    imgPath=os.path.join(trainCropPath,imgName)\n",
    "    \n",
    "    #print(\" is file:\",os.path.isfile(imgPath))\n",
    "    \n",
    "    if os.path.isfile(imgPath):\n",
    "        dfNew = dfNew.append({'Image': row.Image, 'Word': row.Word, 'Writer': row.Writer}, ignore_index=True)    \n",
    "        foundImages+=1\n",
    "    \n",
    "    if indx>100:\n",
    "        break\n",
    "\n",
    "print(\"foundImages:\",foundImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83cf32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Word</th>\n",
       "      <th>Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b06-036.png_106_[481, 1976, 627, 2086]_quest_3...</td>\n",
       "      <td>quest</td>\n",
       "      <td>b06-036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a04-043.png_30_[786, 1482, 957, 1523]_main_2_.png</td>\n",
       "      <td>main</td>\n",
       "      <td>a04-043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m06-106.png_81_[505, 1858, 647, 1926]_flesh_2_...</td>\n",
       "      <td>flesh</td>\n",
       "      <td>m06-106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n06-148.png_45_[753, 2208, 836, 2234]_as_.png</td>\n",
       "      <td>as</td>\n",
       "      <td>n06-148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e04-103.png_96_[462, 908, 665, 1034]_plank_2_.png</td>\n",
       "      <td>plank</td>\n",
       "      <td>e04-103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>m02-066.png_82_[513, 1439, 745, 1522]_interest...</td>\n",
       "      <td>interest</td>\n",
       "      <td>m02-066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>d01-019.png_18_[1185, 1468, 1361, 1544]_who_1_...</td>\n",
       "      <td>who</td>\n",
       "      <td>d01-019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>d06-020.png_2_[825, 1312, 1287, 1391]_possibil...</td>\n",
       "      <td>possibilities</td>\n",
       "      <td>d06-020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>c03-007f.png_19_[359, 2315, 513, 2420]_gral_.png</td>\n",
       "      <td>gral</td>\n",
       "      <td>c03-007f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>h07-084.png_17_[327, 1754, 440, 1851]_let_2_.png</td>\n",
       "      <td>let</td>\n",
       "      <td>h07-084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Image           Word    Writer\n",
       "0   b06-036.png_106_[481, 1976, 627, 2086]_quest_3...          quest   b06-036\n",
       "1   a04-043.png_30_[786, 1482, 957, 1523]_main_2_.png           main   a04-043\n",
       "2   m06-106.png_81_[505, 1858, 647, 1926]_flesh_2_...          flesh   m06-106\n",
       "3       n06-148.png_45_[753, 2208, 836, 2234]_as_.png             as   n06-148\n",
       "4   e04-103.png_96_[462, 908, 665, 1034]_plank_2_.png          plank   e04-103\n",
       "..                                                ...            ...       ...\n",
       "95  m02-066.png_82_[513, 1439, 745, 1522]_interest...       interest   m02-066\n",
       "96  d01-019.png_18_[1185, 1468, 1361, 1544]_who_1_...            who   d01-019\n",
       "97  d06-020.png_2_[825, 1312, 1287, 1391]_possibil...  possibilities   d06-020\n",
       "98   c03-007f.png_19_[359, 2315, 513, 2420]_gral_.png           gral  c03-007f\n",
       "99   h07-084.png_17_[327, 1754, 440, 1851]_let_2_.png            let   h07-084\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5058762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h04-082    362\n",
       "f04-074    353\n",
       "j01-066    351\n",
       "f02-044    345\n",
       "f01-066    344\n",
       "          ... \n",
       "a03-089     69\n",
       "g04-108     67\n",
       "b04-208     59\n",
       "m04-251     48\n",
       "p02-155     31\n",
       "Name: Writer, Length: 1304, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Writer.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db1e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu3",
   "language": "python",
   "name": "tf_gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
