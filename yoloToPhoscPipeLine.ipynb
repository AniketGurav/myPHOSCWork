{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f6c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad873ac5",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "REFER SCRIPT yoloToPhoscPipeLine2.ipynb \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd863f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ffd05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 23:14:36.212625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aniketag/.conda/envs/TensorFlow-2.x-YOLOv3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-30 23:14:36.212653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7497765082582405735\n",
      "]\n",
      "\n",
      "\t YOLO_TYPE: yolov3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 23:14:37.614486: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 23:14:37.615478: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aniketag/.conda/envs/TensorFlow-2.x-YOLOv3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-30 23:14:37.615501: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-30 23:14:37.615544: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aniketag-Latitude-7420): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n",
      "\n",
      "\t self.num_classes= 1\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2.796] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-018o.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2.865] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/k07-059a.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2.959] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a05-121.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.034] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r06-103.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.086] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h01-014.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.169] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n01-057.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.237] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h07-080.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.325] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c04-139.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.387] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-047h.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.422] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m01-032.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.492] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h01-010.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.572] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-026i.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.606] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c04-050.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.672] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/e04-022.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.746] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-018r.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.803] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-072x.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.885] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-042r.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.948] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g04-095.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.049] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a03-034.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.120] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-003u.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.192] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a05-062.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.293] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c04-165.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.369] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m02-109.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.435] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h04-025.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.530] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c04-116.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.609] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a02-020.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.695] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/d06-096.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.769] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m04-251.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.845] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/p02-144.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.917] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/e07-105.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@4.967] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-030x.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.064] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/l04-052.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.256] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a04-027.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.305] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/j01-066.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.379] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c03-000a.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.482] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-007u.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.639] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c02-056.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.727] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h01-030.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.822] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n06-140.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.896] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c04-160.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@5.975] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n06-156.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.036] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/e04-038.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.157] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/p02-022.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@6.225] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m02-048.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.286] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/k02-112.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.347] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-050i.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.441] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g01-043.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.542] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n02-146.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.666] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g01-027.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.763] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h07-071a.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.827] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/f02-030.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@6.918] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-045j.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.008] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n04-107.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.127] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-045d.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.172] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b04-034.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.253] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b06-056.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.303] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m04-209.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.410] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b04-154.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.468] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/l07-065.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.570] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r02-003.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.648] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/e04-124.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.795] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h06-079.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.887] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r06-066.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@7.952] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/m01-038.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.034] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/k07-085.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.188] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b04-026.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.236] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-014.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.325] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/d03-112.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.407] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r02-117.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.488] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-011p.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.563] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b01-127.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.658] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n04-190.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.734] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/b04-089.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.822] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/k04-136.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.948] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-091u.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.015] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-011f.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.091] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r02-081.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.155] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/p06-058.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.272] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-038x.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.370] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/d04-066.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.486] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/r06-137.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.562] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/d07-093.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.667] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a01-003.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.726] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/l04-034.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.835] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n02-104.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@9.885] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/h01-004.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.013] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/f07-019a.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.109] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/k07-134.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.231] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a04-059.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.278] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g06-047k.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.354] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/j07-009.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.398] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a05-069.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.509] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c06-111.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.608] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/f07-081a.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.704] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/c06-031.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.772] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/p06-242.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.843] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/n01-020.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@10.932] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/d04-121.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@11.017] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/g04-081.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@11.116] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/k/phd/yolov5/data/datasets/forms/a03-059.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(\"\\n\\t tf:\",tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "#from yolov3.dataset import Dataset\n",
    "from yolov3.yolov4 import compute_loss1\n",
    "from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from yolov3.utils import read_class_names, image_preprocess#,draw_bbox\n",
    "from yolov3.yolov3 import bbox_iou\n",
    "from yolov3.configs import *\n",
    "from yolov3.utils import load_yolo_weights, detect_image,  nms, read_class_names #image_preprocesss,\n",
    "from supportFunctions import draw_bbox, postprocess_boxes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from yoloModify import yolo33\n",
    "\n",
    "'''\n",
    "    more details regarding Dataset1 is in yolo3PhoscModify2.ipynb\n",
    "'''\n",
    "\n",
    "from yolov3.dataset import Dataset1\n",
    "from yolov3.yolov3 import Create_Yolov3\n",
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "#trainset = Dataset1('train')\n",
    "testset = Dataset1('test')\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "steps_per_epoch = len(testset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed31ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t load weights!!!\n",
      "\n",
      "\t loading complete\n"
     ]
    }
   ],
   "source": [
    "#from yolov3.yolov4 import Create_YoloPhosc\n",
    "TRAIN_MODEL_NAME='yolov3_custom'\n",
    "TRAIN_MODEL_NAME\n",
    "\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    #Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    Darknet = Create_Yolov3(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "    #print(\"Darknet_weights=\",os.path.isfile(Darknet_weights))\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    \n",
    "#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "#yolo=Create_Yolov3(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "yolo=yolo33(input_size=416, channels=3, training=True, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "TRAIN_FROM_CHECKPOINT=True\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        print(\"\\n\\t load weights!!!\")\n",
    "        yolo.load_weights(f\"./checkpoints/{TRAIN_MODEL_NAME}\")\n",
    "        print(\"\\n\\t loading complete\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "'''\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74633db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supportFunctions import draw_bbox, postprocess_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64636fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(counter,image_data, target,orgPath,orgImgName):\n",
    "\n",
    "    \n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "    cv2.imwrite(f'./validation/input.png', image2.numpy()*255)\n",
    "    \n",
    "    #input(\"check111\")\n",
    "    pred_result = yolo(image_data, training=False)\n",
    "\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "        \n",
    "        if i>0:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "                                \n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "\n",
    "    \n",
    "#         print(\"\\n\\t\\t conv pred:\",conv.shape)\n",
    "#         print(\"\\n\\t\\t pred pred=\",pred.shape)\n",
    "    \n",
    "\n",
    "        ''' \n",
    "            (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "\n",
    "            pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "            pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "             #2.pred_result: (1, 52, 52, 2325)\n",
    "            conv: (1, 26, 26, 18)\n",
    "            pred = (1, 26, 26, 3, 6)\n",
    "            pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "            image_data= (1, 416, 416, 3)\n",
    "            pred = (1, 52, 52, 3, 6)\n",
    "            pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "        '''\n",
    "\n",
    "    \n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        #print(\"\\n\\t 1.pred_bbox pred=\",len(pred_bbox))\n",
    "\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "        \n",
    "        label=target[i][0]\n",
    "        print(\"\\n\\t label shape:\",label.shape)\n",
    "        label=label.reshape(-1,775)\n",
    "        print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape,\"\\t label.shape:\",label.shape)\n",
    "        \n",
    "        if 0:\n",
    "            accuracyCalc(pred_bbox,label)\n",
    "        \n",
    "        \n",
    "        if 1:\n",
    "            \n",
    "            \n",
    "            orgImage=cv2.imread(orgPath)\n",
    "            orgImage2=cv2.imread(orgPath)\n",
    "\n",
    "            \n",
    "            #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "            bboxes = postprocess_boxes(pred_bbox, image2.numpy(),orgImage, YOLO_INPUT_SIZE,0.25)\n",
    "            #print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "\n",
    "            if 0:#i==0:\n",
    "                label=target[i]\n",
    "                print(\"\\n\\t label:\",len(label))\n",
    "                print(\"\\n\\t label0:\",label[0].shape)\n",
    "                print(\"\\n\\t label0:\",label[1].shape)\n",
    "                #print(\"\\n\\t\\t\\ label\",label[])\n",
    "                abboxes = postprocess_boxes_Anchors(label[0],pred_bbox, image2.numpy(),416,0.25)\n",
    "\n",
    "\n",
    "            bboxes = nms(bboxes, 0.1, method='nms')\n",
    "\n",
    "            #print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "            #print(\"\\n\\t after nms 2.bboxes =\",bboxes)\n",
    "            #draw_bbox() missing 1 required positional argument: 'bboxes\n",
    "\n",
    "            \n",
    "            #draw_bbox(nm,counter,level, image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence=True,Text_colors=(255, 255, 0), rectangle_colors='', tracking=False)\n",
    "            \n",
    "            #print(\"\\n\\t bboxes len:\",len(bboxes))\n",
    "            \n",
    "            \n",
    "            resultImage = draw_bboxNew(nm,counter,i,255*image2.numpy(),orgImage,orgImage2, bboxes,orgImgName, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "            #resultImage = draw_bbox(nm,counter,i,orgImage, bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "\n",
    "            #cv2.imwrite(f'./validation/{orgImgName}.png',resultImage)\n",
    "            #cv2.imwrite(f'./validation/{counter}.png',orgImage)\n",
    "\n",
    "            #input(\"check\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f57d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxNew(nm,counter,level, image,orgImage, bboxes,orgImgName,orgImage2, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence=True,\n",
    "              Text_colors=(255, 255, 0), rectangle_colors='', tracking=False):\n",
    "    NUM_CLASS = read_class_names(CLASSES)\n",
    "    num_classes = len(NUM_CLASS)\n",
    "    print(\"\\n\\t imag shape---:\",image.shape)\n",
    "    \n",
    "    oh,ow,oc=orgImage.shape\n",
    "    \n",
    "    scaleH,scaleW=oh/416,ow/416\n",
    "    \n",
    "    print(\"original image shape:\",oh,ow,oc)\n",
    "    \n",
    "    try:\n",
    "        batch,image_h, image_w, _ = image.shape\n",
    "    except Exception as e:\n",
    "        batch,image_h, image_w= image.shape\n",
    "\n",
    "\n",
    "    thickness1 = 3\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        #print(\"\\n\\t i=\",i)\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = 0#int(bbox[5]) # phosc change\n",
    "        #print(\"\\n\\t score:\",score,\"\\t class_ind:\",class_ind)\n",
    "        print(\"cor:\",coor)\n",
    "        \n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        #(x11, y11), (x22, y22) =(int(x1*scaleW), int(y1*scaleH)), (int(x2*scaleW), int(y2*scaleH))\n",
    "\n",
    "        x11 = int(x1/(416/ow))\n",
    "        y11 = int(y1/(416/oh))\n",
    "\n",
    "        x22 = int(x2/(416/ow))\n",
    "        y22 = int(y2/(416/oh))\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"\\n\\t x1:\",x1,\"\\t y1:\",y1,\"\\t x2:\",x2,\"\\t y2:\",y2)\n",
    "        print(\"\\n\\t x11:\",x11,\"\\t y11:\",y11,\"\\t x22:\",x22,\"\\t y22:\",y22)\n",
    "        print(\" width:\",(ow/416),\" height::\",(oh/416))\n",
    "        \"\"\"\n",
    "        # print(\"\\n\\t image shape:\",image.shape)\n",
    "        # put object rectangle\n",
    "        #image=cv2.rectangle(image, (x1, y1), (x2, y2),(0,0,0),5)\n",
    "\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        #orgImage = cv2.rectangle(orgImage, (x11, y11), (x22, y22), (255,0,0), 3)\n",
    "        \n",
    "        #orgImage2=cvTest(x1,y1,x2,y2,orgImage2)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        y_ = 416\n",
    "        x_ = 416\n",
    "\n",
    "\n",
    "        targetSize1 = orgImgName.shape[0]\n",
    "        targetSize2 = orgImgName.shape[1]\n",
    "\n",
    "        x_scale = targetSize2 / x_\n",
    "        y_scale = targetSize1 / y_\n",
    "        print(x_scale, y_scale)\n",
    "        img = imageToPredict#cv2.resize(imageToPredict, (targetSize1, targetSize2));\n",
    "        print(\"img size:\",img.shape)\n",
    "        img = np.array(img);\n",
    "\n",
    "        # original frame as named values\n",
    "        (origLeft, origTop, origRight, origBottom) = (x1,y1,x2,y2)#(160, 35, 555, 470)\n",
    "\n",
    "        x = int(np.round(origLeft * x_scale))\n",
    "        y = int(np.round(origTop * y_scale))\n",
    "        xmax = int(np.round(origRight * x_scale))\n",
    "        ymax = int(np.round(origBottom * y_scale))\n",
    "        # Box.drawBox([[1, 0, x, y, xmax, ymax]], img)\n",
    "        #orgImgName2=drawBox([[1, 0, x, y, xmax, ymax]],orgImgName2)\n",
    "        \n",
    "        \n",
    "        orgImgName2 = cv2.rectangle(orgImgName2, (x, y), (xmax, ymax), (255,0,255), 3)\n",
    "        \n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        cv2.imwrite(f'./validation/'+orgImgName+'1.png',orgImgName2)\n",
    "\n",
    "        cv2.imwrite(f'./validation/'+orgImgName+'.png', image)\n",
    "        cv2.imwrite(f'./validation/'+orgImgName+'_.png', orgImage)\n",
    "\n",
    "        #input(\"check!!!\")\n",
    "        \n",
    "    # Line thickness of 9 px\n",
    "    # image = cv2.line(image,(0,0),(10,10), color1,5)\n",
    "    # image = cv2.line(image,(x1,y1),(x2,y2), color1,1)\n",
    "\n",
    "    if len(bboxes)>10 and counter<10:\n",
    "        cv2.imwrite(f'./validation/'+orgImgName+'.png', image)\n",
    "        cv2.imwrite(f'./validation/'+orgImgName+'_.png', orgImage)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab187b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac59c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t image_data= (1, 416, 416, 3)\n",
      "\n",
      "\t allImagesName: ['/home/k/phd/yolov5/data/datasets/forms/k07-059a.png']\n",
      "\n",
      "\t label shape: (1, 52, 52, 3, 775)\n",
      "\n",
      "\t 2.pred_bbox pred= (8112, 171) \t label.shape: (8112, 775)\n",
      " inside post process!!!\n",
      "\n",
      "\t imag shape---: (416, 416, 3)\n",
      "original image shape: 3542 2479 3\n",
      "cor: [[204 204 204]\n",
      " [204 204 204]\n",
      " [208 208 208]\n",
      " [208 208 208]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m orgImgName\u001b[38;5;241m=\u001b[39mallImagesName[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforms/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     18\u001b[0m orgPath\u001b[38;5;241m=\u001b[39mimgPaths\u001b[38;5;241m+\u001b[39morgImgName\n\u001b[0;32m---> 19\u001b[0m \u001b[43mvalidate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43morgPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43morgImgName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#input(\"check!!!\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m:\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mvalidate_step\u001b[0;34m(counter, image_data, target, orgPath, orgImgName)\u001b[0m\n\u001b[1;32m     90\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m nms(bboxes, \u001b[38;5;241m0.1\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#print(\"\\n\\t after nms 2.bboxes =\",bboxes)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#draw_bbox() missing 1 required positional argument: 'bboxes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#print(\"\\n\\t bboxes len:\",len(bboxes))\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m resultImage \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_bboxNew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43morgImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43morgImage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43morgImgName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASSES\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYOLO_COCO_CLASSES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangle_colors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mdraw_bboxNew\u001b[0;34m(nm, counter, level, image, orgImage, bboxes, orgImgName, orgImage2, CLASSES, show_label, show_confidence, Text_colors, rectangle_colors, tracking)\u001b[0m\n\u001b[1;32m     29\u001b[0m (x1, y1), (x2, y2) \u001b[38;5;241m=\u001b[39m (coor[\u001b[38;5;241m0\u001b[39m], coor[\u001b[38;5;241m1\u001b[39m]), (coor[\u001b[38;5;241m2\u001b[39m], coor[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#(x11, y11), (x22, y22) =(int(x1*scaleW), int(y1*scaleH)), (int(x2*scaleW), int(y2*scaleH))\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m x11 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y11 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y1\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m416\u001b[39m\u001b[38;5;241m/\u001b[39moh))\n\u001b[1;32m     35\u001b[0m x22 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x2\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m416\u001b[39m\u001b[38;5;241m/\u001b[39mow))\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# for counter,(image_data, target,allImagesName) in enumerate(trainset):\n",
    "from supportFunctions import draw_bbox, postprocess_boxes\n",
    "imgPaths=\"/home/aniketag/Documents/phd/yolov5/data//datasets//forms//\"\n",
    "for counter,(image_data, target,allImagesName) in enumerate(testset):\n",
    "    nm=str(np.random.randint(10000))+\".png\"\n",
    "    nm=str(counter)+\".png\"\n",
    "    print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "\n",
    "    '''\n",
    "    print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "    print(\"\\n\\t target:\",target[0][0].shape)\n",
    "    print(\"\\n\\t target:\",target[1][0].shape)\n",
    "    print(\"\\n\\t target:\",target[2][0].shape)\n",
    "    '''\n",
    "    print(\"\\n\\t allImagesName:\",allImagesName)\n",
    "    \n",
    "    orgImgName=allImagesName[0].split(\"forms/\")[1]\n",
    "    orgPath=imgPaths+orgImgName\n",
    "    validate_step(counter,image_data, target,orgPath,orgImgName)\n",
    "    #input(\"check!!!\")\n",
    "    \n",
    "    if counter==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ae2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32566597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def drawBox(boxes, image):\n",
    "    for i in range(0, len(boxes)):\n",
    "        # changed color and width to make it visible\n",
    "        cv2.rectangle(image, (boxes[i][2], boxes[i][3]), (boxes[i][4], boxes[i][5]), (255, 0, 0), 3)\n",
    "    #cv2.imshow(\"img\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #cv2.imwrite(f'./validation/'+'temp.png', image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def cvTest(x1,y1,x2,y2,imageToPredict):\n",
    "    # imageToPredict = cv2.imread(\"img.jpg\", 3)\n",
    "    #imageToPredict = cv2.imread(\"49466033\\\\img.png \", 3)\n",
    "    #print(imageToPredict.shape)\n",
    "\n",
    "    # Note: flipped comparing to your original code!\n",
    "    # x_ = imageToPredict.shape[0]\n",
    "    # y_ = imageToPredict.shape[1]\n",
    "    \n",
    "    \"\"\"\n",
    "    y_ = imageToPredict.shape[0]\n",
    "    x_ = imageToPredict.shape[1]\n",
    "    \"\"\"\n",
    "    y_ = 416\n",
    "    x_ = 416\n",
    "    \n",
    "    \n",
    "    targetSize1 = imageToPredict.shape[0]\n",
    "    targetSize2 = imageToPredict.shape[1]\n",
    "    \n",
    "    x_scale = targetSize2 / x_\n",
    "    y_scale = targetSize1 / y_\n",
    "    print(x_scale, y_scale)\n",
    "    img = imageToPredict#cv2.resize(imageToPredict, (targetSize1, targetSize2));\n",
    "    print(\"img size:\",img.shape)\n",
    "    img = np.array(img);\n",
    "\n",
    "    # original frame as named values\n",
    "    (origLeft, origTop, origRight, origBottom) = (x1,y1,x2,y2)#(160, 35, 555, 470)\n",
    "\n",
    "    x = int(np.round(origLeft * x_scale))\n",
    "    y = int(np.round(origTop * y_scale))\n",
    "    xmax = int(np.round(origRight * x_scale))\n",
    "    ymax = int(np.round(origBottom * y_scale))\n",
    "    # Box.drawBox([[1, 0, x, y, xmax, ymax]], img)\n",
    "    img=drawBox([[1, 0, x, y, xmax, ymax]], img)\n",
    "    return img\n",
    "\n",
    "#cvTest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
